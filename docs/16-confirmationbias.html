<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.310">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="description" content="This open educational resource contains information to improve statistical inferences, design better experiments, and report scientific research more transparently.">
<title>Improving Your Statistical Inferences - 16&nbsp; Confirmation Bias and Organized Skepticism</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./15-researchintegrity.html" rel="prev">
<link href="./images/logos/favicon.ico" rel="icon">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-0MK2WTGRM3"></script><script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-0MK2WTGRM3', { 'anonymize_ip': true});
</script><link rel="stylesheet" href="include/booktem.css">
<link rel="stylesheet" href="include/style.css">
<link rel="stylesheet" href="include/webex.css">
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./16-confirmationbias.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Confirmation Bias and Organized Skepticism</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Improving Your Statistical Inferences</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/Lakens/statistical_inferences" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Improving-Your-Statistical-Inferences.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Improving-Your-Statistical-Inferences.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
</div>
    <a href="https://twitter.com/intent/tweet?url=%7Curl%7C" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-pvalue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Using <em>p</em>-values to test a hypothesis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-errorcontrol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Error control</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-likelihoods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Likelihoods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-bayes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Bayesian statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-questions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Asking Statistical Questions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-effectsize.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Effect Sizes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-CI.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Confidence Intervals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-samplesizejustification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Sample Size Justification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-equivalencetest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Equivalence Testing and Interval Hypotheses</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-sequential.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Sequential Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-meta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Meta-analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-bias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bias detection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-prereg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Preregistration and Transparency</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-computationalreproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Computational Reproducibility</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15-researchintegrity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Research Integrity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16-confirmationbias.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Confirmation Bias and Organized Skepticism</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./changelog.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Change Log</span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#confirmation-bias-in-science" id="toc-confirmation-bias-in-science" class="nav-link active" data-scroll-target="#confirmation-bias-in-science"><span class="header-section-number">16.1</span> Confirmation bias in science</a></li>
  <li>
<a href="#organized-skepticism" id="toc-organized-skepticism" class="nav-link" data-scroll-target="#organized-skepticism"><span class="header-section-number">16.2</span> Organized Skepticism</a>
  <ul class="collapse">
<li><a href="#error-control" id="toc-error-control" class="nav-link" data-scroll-target="#error-control"><span class="header-section-number">16.2.1</span> Error control</a></li>
  <li><a href="#preregistration" id="toc-preregistration" class="nav-link" data-scroll-target="#preregistration"><span class="header-section-number">16.2.2</span> Preregistration</a></li>
  <li><a href="#independent-replication-studies" id="toc-independent-replication-studies" class="nav-link" data-scroll-target="#independent-replication-studies"><span class="header-section-number">16.2.3</span> Independent Replication Studies</a></li>
  <li><a href="#peer-review" id="toc-peer-review" class="nav-link" data-scroll-target="#peer-review"><span class="header-section-number">16.2.4</span> Peer Review</a></li>
  <li><a href="#double-checking-errors." id="toc-double-checking-errors." class="nav-link" data-scroll-target="#double-checking-errors."><span class="header-section-number">16.2.5</span> Double-Checking Errors.</a></li>
  <li><a href="#the-devils-advocate" id="toc-the-devils-advocate" class="nav-link" data-scroll-target="#the-devils-advocate"><span class="header-section-number">16.2.6</span> The Devil’s Advocate</a></li>
  <li><a href="#adversarial-collaborations" id="toc-adversarial-collaborations" class="nav-link" data-scroll-target="#adversarial-collaborations"><span class="header-section-number">16.2.7</span> Adversarial Collaborations</a></li>
  <li><a href="#red-team-science" id="toc-red-team-science" class="nav-link" data-scroll-target="#red-team-science"><span class="header-section-number">16.2.8</span> Red Team Science</a></li>
  <li><a href="#blinding" id="toc-blinding" class="nav-link" data-scroll-target="#blinding"><span class="header-section-number">16.2.9</span> Blinding</a></li>
  <li><a href="#separating-theorists-from-experimentalists" id="toc-separating-theorists-from-experimentalists" class="nav-link" data-scroll-target="#separating-theorists-from-experimentalists"><span class="header-section-number">16.2.10</span> Separating Theorists from Experimentalists</a></li>
  <li><a href="#method-of-multiple-working-hypotheses" id="toc-method-of-multiple-working-hypotheses" class="nav-link" data-scroll-target="#method-of-multiple-working-hypotheses"><span class="header-section-number">16.2.11</span> Method of multiple working hypotheses</a></li>
  </ul>
</li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">16.3</span> Conclusion</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/Lakens/statistical_inferences/edit/master/16-confirmationbias.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/Lakens/statistical_inferences/issues/new" class="toc-action">Report an issue</a></p><p><a href="https://github.com/Lakens/statistical_inferences/blob/master/16-confirmationbias.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-confirmationbias" class="quarto-section-identifier"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Confirmation Bias and Organized Skepticism</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><blockquote class="blockquote">
<p>I cannot give any scientist of any age better advice than this: The intensity of the conviction that a hypothesis is true has no bearing on whether it is true or not. The importance of the strength of our conviction is only to provide a proportionately strong incentive to find out if the hypothesis will stand up to critical evaluation. <em>Medawar, 1979, Advice to a Young Scientist</em></p>
</blockquote>
<p>Being a scientist is a rewarding but challenging career path. Doing science can lead to the intellectual satisfaction of making discoveries or increasing our understanding about important questions, the rewarding feeling of contributing to solutions to important problems society faces, interacting with stimulating colleagues, recognition from peers and the general public, as well as the possibility of a decent income if you become an internationally sought-after expert in your field. At the same time, it can be a difficult career that requires hard work, uncertainty about your future career, times where you have little success in advancing your knowledge, experiencing competitiveness or even animosity towards other scientists, and a feeling of pressure to achieve goals <span class="citation" data-cites="NAP12192">(<a href="references.html#ref-NAP12192" role="doc-biblioref">National Academy of Sciences et al., 2009</a>)</span>. Although science is a collective endeavor, scientists often has a strong personal commitment to their work. They are motivated to succeed, and disappointed if their work is not successful.</p>
<p>In his book “Modern science and the nature of life” William Beck <span class="citation" data-cites="beck_modern_1957">(<a href="references.html#ref-beck_modern_1957" role="doc-biblioref">1957</a>)</span> writes:</p>
<blockquote class="blockquote">
<p>Each successive step in the method of science calls for a greater emotional investment and adds to the difficulty of remaining objective. When the ego is involved, self-criticism may come hard (Who ever heard of two scientists battling to prove the other right?). One has always a vested interest in the successful outcome and, whether we enjoy admitting it of not, each of us feels the pressure to succeed, to blaze ‘new trails’ perhaps before we have mastered the old, to remain productive and therefore admired, to embark obsessively (as did Sigmund( upon a romantic crusade towards epic truth. It is apparent, therefore, how latent neurotic tendencies may impinge upon and distort the clean mandates of scientific method and may generate error, unrealistic values, anxiety, and – let’s face it, since science is done behind closed doors – dishonesty. Because scientists are human and science is not, as in all fields the thin thread of integrity is sometimes strained to break.</p>
</blockquote>
<p>The recognition that science is a human activity has not gone unnoticed. In 1620 Francis Bacon wrote the book ‘Novum Organum’ (or ‘New Method’) which provided a first description of a modern scientific method, with a focus on empiricism and inductive reasoning. Bacon already realized more than 400 years ago that people are not passive observers, and provides a very early description of what we would now call <em>confirmation bias</em>:</p>
<blockquote class="blockquote">
<p>The human understanding, when any proposition has been once laid down (either from general admission and belief, or from the pleasure it affords), forces everything else to add fresh support and confirmation; and although most cogent and abundant instances may exist to the contrary, yet either does not observe or despises them, or gets rid of and rejects them by some distinction, with violent and injurious prejudice, rather than sacrifice the authority of its first conclusions. It was well answered by him who was shown in a temple the votive tablets suspended by such as had escaped the peril of shipwreck, and was pressed as to whether he would then recognize the power of the gods, by an inquiry, But where are the portraits of those who have perished in spite of their vows? All superstition is much the same, whether it be that of astrology, dreams, omens, retributive judgment, or the like, in all of which the deluded believers observe events which are fulfilled, but neglect and pass over their failure, though it be much more common. But this evil insinuates itself still more craftily in philosophy and the sciences, in which a settled maxim vitiates and governs every other circumstance, though the latter be much more worthy of confidence. Besides, even in the absence of that eagerness and want of thought (which we have mentioned), it is the peculiar and perpetual error of the human understanding to be more moved and excited by affirmatives than negatives, whereas it ought duly and regularly to be impartial; nay, in establishing any true axiom the negative instance is the most powerful.</p>
</blockquote>
<p>In a classic paper on confirmation bias, Nickerson <span class="citation" data-cites="nickerson_confirmation_1998">(<a href="references.html#ref-nickerson_confirmation_1998" role="doc-biblioref">1998</a>)</span> defines confirmation bias as <strong>the seeking or interpreting of evidence in ways that are partial to existing beliefs, expectations, or a hypothesis in hand.</strong> The human factors that influence (or bias) scientific knowledge generation received relatively little attention from philosophers of science, even though it would be naïve to believe that scientists objectively pursuit the truth. As the philosopher of science Chang <span class="citation" data-cites="chang_realism_2022">(<a href="references.html#ref-chang_realism_2022" role="doc-biblioref">2022</a>)</span> writes:</p>
<blockquote class="blockquote">
<p>There is a tendency in the philosophy of science to present the scientist as a ghostly being that just has degrees of belief in various descriptive statements, which are adjusted according to some rules of rational thinking (e.g., Bayes’s theorem) that remove any need for real judgement. Whatever does not fit into this bizarre and impoverished picture, we tend to denigrate as matters of ‘mere’ psychology or sociology.</p>
</blockquote>
<p>The sociologist of science Robert Merton <span class="citation" data-cites="merton_note_1942">(<a href="references.html#ref-merton_note_1942" role="doc-biblioref">1942</a>)</span> believed that “Four sets of institutional imperatives - universalism, communism, disinterestedness, organized scepticism - comprise the ethos of modern science.” <em>Universalism</em> means that “The acceptance or rejection of claims entering the lists of science is not to depend on the personal or social attributes of their protagonist”. <em>Communism</em> means that “The substantive findings of science are a product of social collaboration and are assigned to the community”. Scientist do not own their theories – at best they receive recognition for developing their ideas. As Merton writes “Secrecy is the antithesis of this norm; full and open communication its enactment.” <em>Disinterestedness</em> occurs not on the individual level – a scientist can have a passions and motivations – but on the institutional level. The institution of science has disinterestedness as a norm, which means that claims should be truthful, and not spurious. According to Merton, scientists are subject to rigorous policing – scientists are accountable to their peers, who will check their work, and therefore only disinterestedness will lead to claims that survive scrutiny. And finally, <em>organized skepticism</em> means the “scrutiny of beliefs in terms of empirical and logical criteria”. Claims are only accepted after they have survived scrutiny by peers.</p>
<p>As with any norm, not all individuals subscribe to all norms, and more importantly, not everyone behaves in line with norms (at least not all the time). For example, a common norm is to be truthful when you talk to others. Yet, even if we subscribe to the norm to be truthful, we might not always tell the truth ourselves. And we might believe others lie even more often than we do. This is exactly the pattern that Anderson and colleagues <span class="citation" data-cites="anderson_normative_2007">(<a href="references.html#ref-anderson_normative_2007" role="doc-biblioref">2007</a>)</span> found in a survey among US scientists (see <a href="#fig-norms">Figure&nbsp;<span>16.1</span></a>). Scientists subscribed to Mertonian norms (the maximum possible score is 12). They also admit not to always follow these norms in their own behavior, and they believe others follow these norms even less. The pattern is the opposite for counternorms (e,g, secrecy, self-interestedness, etc.).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-norms" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/normsanderson.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;16.1: Means of Normative and Counternormative Subscription and Behavior from Anderson et al., (2007).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>When asked, scientists don’t see members of their own profession as being objective at all. In an interesting series of interviews with scientists involved in the Apollo moon landing, Mittroff <span class="citation" data-cites="mitroff_norms_1974">(<a href="references.html#ref-mitroff_norms_1974" role="doc-biblioref">1974</a>)</span> concludes: “Every one of the scientists interviewed on the first round of interviews indicated that they thought the notion of the objective, emotionally disinterested scientist naïve”. His article is full of excellent quotes that illustrate this conclusion, such as:</p>
<blockquote class="blockquote">
<p>Scientist B: The uninvolved, unemotional scientist is just as much a fiction as the mad scientist who will destroy the world for knowledge. Most of the scientists I know have theories and are looking for data to support them; they’re not sorting impersonally through the data looking for a theory to fit the data. You’ve got to make a clear distinction between not being objective and cheating. A good scientist will not be above changing his theory if he gets a preponderance of evidence that doesn’t support it, but basically he’s looking to defend it. Without [emotional] commitment one wouldn’t have the energy, the drive to press forward sometimes against extremely difficult odds. You don’t consciously falsify evidence in science but you put less priority on a piece of data that goes against you. No reputable scientist does this consciously but you do it subconsciously.</p>
</blockquote>
<blockquote class="blockquote">
<p>Scientist G: Every scientific idea needs a personal representative who will defend and nourish that idea so that it doesn’t suffer a premature death.</p>
</blockquote>
<p>These interviews reveal that scientists believe a commitment to a specific idea or theory is a necessity if you want to motivate yourself to keep exploring an idea, even when the going gets tough, or to make sure an idea is not too easily dismissed. In other words, confirmation bias could even have a positive role to play.</p>
<p>Although there are now philosophers of science who recognize that science is a social process <span class="citation" data-cites="douglas_science_2009 longino_science_1990">(<a href="references.html#ref-douglas_science_2009" role="doc-biblioref">Douglas, 2009</a>; <a href="references.html#ref-longino_science_1990" role="doc-biblioref">Longino, 1990</a>)</span>, most researchers who study human factors in scientific research come from fields such as <strong>psychology of science</strong>, <strong>sociology of science</strong>, <strong>science and technology studies</strong>, or <strong>meta-science</strong>. Researchers in these fields try to describe ways in which researcher fall victim to confirmation bias, analyze the underlying mechanisms that cause confirmation, and propose interventions to reduce the effect of confirmation bias in science.</p>
<p>For example, Mahoney <span class="citation" data-cites="mahoney_psychology_1979">(<a href="references.html#ref-mahoney_psychology_1979" role="doc-biblioref">1979</a>)</span> reviewed the literature related to the common textbook description of scientists as objective, rational, open-minded, intelligent, acting with integrity, and openly and cooperatively sharing knowledge, and concluded:</p>
<ol type="1">
<li>The scientist is not immune to perceptual biases and is frequently quite emotional in response to technical and epistemological matters.</li>
<li>It remains to be demonstrated that scientists are more logical than nonscientists in the conduct and interpretation of their work.</li>
<li>The scientist may sometimes be unreceptive to relevant data and – particularly in the case of theorists - prone to hasty speculation and dogmatic tenacity.</li>
<li>Although scientists generally have higher IQs than non-scientists, it remains to be demonstrated that small intellectual differences have a substantial impact on professional competence or contribution.</li>
<li>Reports of data fabrication and experimenter bias suggest that such phenomena are neither rare nor trivial.</li>
<li>Scientists tend to be secretive and suspicious until they have established a public priority claim to their work; disputes over personal credit and priority frequently result in bitter arguments.</li>
</ol>
<p>So why does science still seem to work, given all these all too human limitations that scientists display? One way to look at science is as a method that groups of people use to make claims while implementing procedures that aim to reduce the role of confirmation bias. Although science encompasses much more than a set of rules to reduce confirmation bias, many practices, such as peer review, performing independent replication studies, and specifying the alpha level of a test before looking at the data, can only be understood from this perspective. Some scientists consider active attempts to resist confirmation bias an essential feature of good science. As Feynman <span class="citation" data-cites="feynman_cargo_1974">(<a href="references.html#ref-feynman_cargo_1974" role="doc-biblioref">1974</a>)</span> writes: “The first principle is that you must not fool yourself - and you are the easiest person to fool.”</p>
<section id="confirmation-bias-in-science" class="level2" data-number="16.1"><h2 data-number="16.1" class="anchored" data-anchor-id="confirmation-bias-in-science">
<span class="header-section-number">16.1</span> Confirmation bias in science</h2>
<p>Wason <span class="citation" data-cites="wason_failure_1960">(<a href="references.html#ref-wason_failure_1960" role="doc-biblioref">1960</a>)</span> created a simple task to examine how people test hypotheses. You first get a series of 3 numbers. Your task is to develop a hypothesis about the underlying rule that has generated these three numbers. You can then test the underlying rule by suggesting a new set of three numbers, and you will be told if the set of three numbers follows the rule you are supposed to discover, yes or no. Let’s give it a try. I will give you the following 3 numbers: 2, 4, 8.</p>
<p>You can think of a rule that has generated this set of three numbers. To test your rule, you can provide a new set of three numbers. Take a moment to think of which 3 numbers you would want to suggest, and then you will hear if the numbers follow to the rule, or not. Let’s say you have decided to suggest three numbers such as 3, 6, 12, or 5, 10, 20. These numbers are in line with a rule ‘the first numbered is doubled, and then doubled again’. If you would have suggested three numbers like this, you would have heard they follow the rule you were supposed to discover. However, had you provided the three numbers 2, 3, 9, you would <em>also</em> have received the answer that this set of three numbers follows the underlying rule. The rule to be discovered was ‘three numbers in increasing order of magnitude’.</p>
<p>If you are like most people who complete the Wason task, you tested a set of three numbers that would confirm the rule you had in mind. Having the rule confirmed tells you your rule might be correct, but that many other rules can also be correct. Testing a set of three numbers that you predict would not follow the rule, such as 1, 2, 3, and learning this set of three numbers actually follows to underlying rule, tells you with certainty that the rule you had in mind is incorrect. Confirming and falsifying predictions is both important, but people seem in general less inclined to try to prove themselves wrong. This knowledge about human psychology is useful to have, because we can use it to develop methods and procedures to counteract negative effects that arise from our inclination to want to confirm our hypotheses.</p>
<p>In his paper titled “Pathological Science” Langmuir <span class="citation" data-cites="langmuir_pathological_1989">(<a href="references.html#ref-langmuir_pathological_1989" role="doc-biblioref">1989</a>)</span> discusses two examples of confirmation bias in physics. The first example is the Davis-Barnes effect, which described unexpected behavior of alpha particles interacting with electrons in a magnetic field, and the second example is N-rays, a hypothesized form of radiation inspired by the discovery of X-rays, described by French physicist Blondlot in 1903, and initially confirmed by others physicists. In both cases skepticism of the initial findings led other scientists to perform an on-site inspection of the experiment being performed, who concluded the results were due to observer error. As Langmuir writes: “These are cases where there is no dishonesty involved but where people are tricked into false results by a lack of understanding about what human beings can do to themselves in the way of being led astray by subjective effects, wishful thinking or threshold interactions.”</p>
<p>There are also cases where dishonesty <em>is</em> involved. Sometimes scientists commit outright scientific fraud, and fabricate data, but it is not always clear where to draw the dividing line between intentional and unintentional bias. For example, in a famous case of the geneticist Gregory Mendel who studied heredity in pea plants. Later re-analyses of his data by the statistician and geneticist Ronald Fisher revealed that his results are implausibly close to predicted outcomes <span class="citation" data-cites="fisher_has_1936">(<a href="references.html#ref-fisher_has_1936" role="doc-biblioref">Fisher, 1936</a>)</span>. Although there is agreement that the results are statistically implausible, it is difficult to pinpoint a cause. The statistical implausibility could be due to incorrectly reporting details of the experiment, classification errors, or even an assistant feeling some pressure to report results in line with expectations <span class="citation" data-cites="radick_mendel_2022">(<a href="references.html#ref-radick_mendel_2022" role="doc-biblioref">Radick, 2022</a>)</span>. One reason to embrace open science practices is so that the research community will benefit from greater transparency about what happened in situations where researchers raise doubts about the validity of results.</p>
<p>It is not just scientists who <strong>fabricate data</strong> – students do this as well. In an incredibly interesting paper documenting attempts to perform a replication study as a class assignment, Azrin and colleagues <span class="citation" data-cites="azrin_control_1961">(<a href="references.html#ref-azrin_control_1961" role="doc-biblioref">1961</a>)</span> found that many of the students fabricated all or part of the data because following the experimental procedure was too difficult. In one class experiment, only a single student reported having trouble performing the experiment as it was supposed to be carried out. When students discussed the experiment later during the course, and the honest student admitted that they had tried to perform the experiment 6 times, but failed and gave up, 8 other students suddenly also admitted that they had problems following the experimental procedure, and had deviated substantially from the instructions. Even worse, in another class assignment replicating the same study, when one student asked “I’m having trouble with my experiment; can you tell me how you did yours?” 12 out of 19 students questioned this way readily admitted to fabricating data to this fellow student.</p>
<p>We can imagine many reasons why students would fabricate data, such as not wanting to admit they failed at following experimental instructions and feeling stupid, or simply fabricating data to not have to do any actual work. In a class I co-taught with a colleague many years ago students also fabricated data. We had asked them to collect data for a short survey from 10 friends of family members, just so that they would have real data to analyze during the course. At the time we did not realize the survey students created (also as part of the course) end up being much longer than a few minutes, nor did we realize that many students found it unpleasant to have to ask 10 people for a favor. None of the students told us they had difficulties following the instructions – instead many of them fabricated surveys until they could hand in 10 surveys. As teachers, we had obviously asked our students to complete an unreasonable task. But had a student honestly told us about the difficulty they experienced collecting the data, we would have adjusted the assignment (as we did the year after). The code of conduct for research integrity applies to staff and students. Whenever you feel pressure and are considering to violate the code of conduct (for example by fabricating data), don’t! Instead, bring the problem to the attention of a teacher, or a confidential advisor if you are more comfortable talking to someone else.</p>
<p>As discussed in the section on questionable research practices, sometimes researchers opportunistically use flexibility in their research methods to increase the probability of finding support for their hypotheses. It is often unclear to which extent researchers are aware of how problematic this behavior is, and therefore it is difficult to establish when this behavior is simply dishonest, and when it is bias through a lack of understanding. These practices have been known for a long time. Kish <span class="citation" data-cites="kish_statistical_1959">(<a href="references.html#ref-kish_statistical_1959" role="doc-biblioref">1959</a>)</span> already mentioned as one misuse of statistical tests: “First, there is”hunting with a shot-gun” for significant differences. […] The keen-eyed researcher hunting through the results of one thousand random tosses of perfect coins would discover and display about fifty “significant” results (at the P = .05 level). Perhaps the problem has become more acute now that high-speed computers allow hundreds of significance tests to be made.”</p>
<p>Barber <span class="citation" data-cites="barber_pitfalls_1976">(<a href="references.html#ref-barber_pitfalls_1976" role="doc-biblioref">1976</a>)</span> reminds us that “Since experiments are designed and carried out by fallible individuals, they have as many pitfalls as other human endeavors” and provides an extensive overview of ways researchers might bias their conclusions. He lists many ways in which researchers can bias the results they observe, either as experimenter (e.g., treating people in the experimental condition slightly differently than people in the control condition) or as investigator (e.g., analyzing data in many different ways until a significant result has been observed). These concerns only received widespread attention in psychology at the start of the replication crisis, for example through the article ‘False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant’ <span class="citation" data-cites="simmons_false-positive_2011">(<a href="references.html#ref-simmons_false-positive_2011" role="doc-biblioref">Simmons et al., 2011</a>)</span>.</p>
</section><section id="organized-skepticism" class="level2" data-number="16.2"><h2 data-number="16.2" class="anchored" data-anchor-id="organized-skepticism">
<span class="header-section-number">16.2</span> Organized Skepticism</h2>
<p>By now it is clear that there is a risk that scientists will let their biases influence the claims they make. Following Merton’s <span class="citation" data-cites="merton_note_1942">(<a href="references.html#ref-merton_note_1942" role="doc-biblioref">1942</a>)</span> notion of <strong>organized skepticism</strong> there are a number of practices in science that exist to, as far as possible, counteract biases by enabling claims to be subjected to critical scrutiny.</p>
<section id="error-control" class="level3" data-number="16.2.1"><h3 data-number="16.2.1" class="anchored" data-anchor-id="error-control">
<span class="header-section-number">16.2.1</span> Error control</h3>
<p>When William Gosset (also known as Student of Student’s <em>t</em>-test) wrote an internal document for the Guinness brewery detailing the usefulness of using error probabilities to “enable us to form a judgment of-the number and nature of the fresh experiments necessary to establish or disprove various hypotheses which we are now entertaining.” Already in this first paper on the topic Gosset recognizes that it is useful to specify the error rate that will be used to draw conclusions in some objective manner, as: “it.is generally agreed that to leave the rejection of experiments entirely to the discretion-of the experimenter is dangerous, as he is likely to be biassed. Hence it has been proposed to adopt criterion depending on the probability of such a wide error occurring in the given number of observations.” A similar point is made by the biostatistician Irwin Bross <span class="citation" data-cites="bross_critical_1971">(<a href="references.html#ref-bross_critical_1971" role="doc-biblioref">1971</a>)</span>: “He writes: “in conformity with the linguistic patterns in setting conventions it is natural to use a round number like 5%. Such round numbers serve to avoid any suggestion that the critical value has been gerrymandered or otherwise picked to prove a point in a particular study.” In short, “If researchers are allowed to set the alpha level after looking at the data, there is a possibility that confirmation bias (or more intentional falsification-deflecting strategies)” <span class="citation" data-cites="uygun_tunc_epistemic_2023">(<a href="references.html#ref-uygun_tunc_epistemic_2023" role="doc-biblioref">Uygun Tunç et al., 2023</a>)</span>. The use of a fixed alpha level (in most fields of 5%) is therefore an example of organized skepticism. Claims need to pass a criterion that controls erroneous conclusions before taken seriously.</p>
</section><section id="preregistration" class="level3" data-number="16.2.2"><h3 data-number="16.2.2" class="anchored" data-anchor-id="preregistration">
<span class="header-section-number">16.2.2</span> Preregistration</h3>
<p>In the chapter on ‘Investigator Data Analysis Effects’ Barber <span class="citation" data-cites="barber_pitfalls_1976">(<a href="references.html#ref-barber_pitfalls_1976" role="doc-biblioref">1976</a>)</span> presents a first example of a pitfall that concerns choosing the hypothesis after looking at the data: “A serious potential pitfall is present when investigators collect a large amount of data and have not pre-planned how they are to analyze the data. […] The major problem here is that the investigator decides how the data are to be analyzed after he has”eyeballed” or studied the data.” A researcher can use a fixed alpha level before looking at the data, but this is not sufficient to control erroneous conclusions if they subsequently pick the test they want to perform after identifying interesting patterns in the data. The solution to this problem is the preregistration of an analysis plan. Once again, preregistration is a form of organized skepticism. Researchers are not simply trusted to report their planned analyses in an unbiased manner. Instead, they are asked to use a method of testing hypotheses where peers can scrutinize whether the analyses were indeed planned before the researchers had access to the data. It is perfectly possible that deviation from an analyses plan withstand scrutiny by peers <span class="citation" data-cites="lakens_value_2019">(<a href="references.html#ref-lakens_value_2019" role="doc-biblioref">Lakens, 2019</a>)</span>, but researchers should allow others to transparently evaluate if the tests were not chosen opportunistically. When researchers in a field are expected to preregister their research (such as in clinical trials) preregistration is an institutional implementation of organized skepticism. The topic of preregistration is discussed in more detail in the chapter on <a href="13-prereg.html">preregistration and transparency</a>.</p>
</section><section id="independent-replication-studies" class="level3" data-number="16.2.3"><h3 data-number="16.2.3" class="anchored" data-anchor-id="independent-replication-studies">
<span class="header-section-number">16.2.3</span> Independent Replication Studies</h3>
<p>After a study has been performed and a conclusion has been reached, a subsequent step where the claim is scrutinized is when other researchers try to independently replicate the finding. As Neher <span class="citation" data-cites="neher_probability_1967">(<a href="references.html#ref-neher_probability_1967" role="doc-biblioref">1967</a>)</span> writes: “Individual researchers often fail to recognize crucial but subtle characteristics of their sample and of their study, mechanical errors of recording and calculation, and errors arising from the researchers’ own influence and biases.” Independent replication provides a method to explore the extent to which such characteristics caused an effect. The usefulness of independent replication in psychology was already pointed out by Mack <span class="citation" data-cites="mack_need_1951">(<a href="references.html#ref-mack_need_1951" role="doc-biblioref">1951</a>)</span> and Lubin <span class="citation" data-cites="lubin_replicability_1957">(<a href="references.html#ref-lubin_replicability_1957" role="doc-biblioref">1957</a>)</span>. Independent replication is equally important in other fields, such as particle physics <span class="citation" data-cites="junk_reproducibility_2020">(<a href="references.html#ref-junk_reproducibility_2020" role="doc-biblioref">Junk &amp; Lyons, 2020</a>)</span>.</p>
<p>If a finding can be independently replicated by other researchers, it becomes less likely that the original claim is impacted by subtle characteristics of the original study. It is also less likely that the original study suffered from more serious problems, such as fraud or inflated Type 1 error rates due to flexibility in the data analysis. A successful independent replication can not completely take away such concerns. As Bakan <span class="citation" data-cites="bakan_method_1967">(<a href="references.html#ref-bakan_method_1967" role="doc-biblioref">1967</a>)</span> warns: “If one investigator is interested in replicating the investigation of another investigator, he should carefully take into account the possibility of suggestion, or his willingness to accept the results of the earlier investigator (particularly if the first investigator has prestige for the second investigator). He should lake careful cognizance of possible motivation for showing the earlier investigator to be in error, etc.” It is always possible that the researchers involved in the independent replication shared the same systematic biases, or simply happened to observe a Type 1 error as well, but with each successful independent replication such concerns become less likely. A non-successful independent replication is more difficult to interpret. The researcher performing the replication might have been motivated to botch the experiment because they wanted to find a non-significant result. There might have been actual differences between the study studies that need to be explored in subsequent studies. But failed independent replications raise questions about the generalizability of claims, and if multiple people fail in independently replicating a study, that is a cause for concern.</p>
</section><section id="peer-review" class="level3" data-number="16.2.4"><h3 data-number="16.2.4" class="anchored" data-anchor-id="peer-review">
<span class="header-section-number">16.2.4</span> Peer Review</h3>
<p>The prototypical example of organized skepticism in science is the peer review process. As the philosopher of science Helen Longino <span class="citation" data-cites="longino_science_1990">(<a href="references.html#ref-longino_science_1990" role="doc-biblioref">1990</a>)</span> writes: “I have argued both that criticism from alternative points of view is required for objectivity and that the subjection of hypotheses and evidential reasoning to critical scrutiny is what limits the intrusion of individual subjective preference into scientific knowledge. […] Peer review is often pointed to as the standard avenue for such criticism”.</p>
<p>The <strong>peer review</strong> process works as follows. When a scientist has written a manuscript they submit it to the scientific journal of their choice. Journals have editors who process submitted manuscripts. An editor will first check if the manuscript seems like it would be of interest to their readership, and if it seems to be of sufficient quality. If so, the manuscript is sent out for peer review. Scientific peers with expertise on the topic discussed in the manuscript will be approached over email, and asked if they want to provide a review. Editors typically try to find at least two peer reviewers, but sometimes more. Peer reviewers get access to the manuscript, but they are typically not allowed to share it with others – in other words, in most cases the peer review process is confidential. Peer reviewers write their reviews for free, as part of their job as a scientist, and they typically get a number of weeks to complete the review. The editor will then read the reviews, and decide if the manuscript is rejected (the editor declines to publish it), accepted (the manuscript is considered to be of sufficient quality to publish it), or if the manuscript needs to be revised (which means authors address criticism and suggestions by the peer reviewers, and resubmit the manuscript to the journal). Sometimes there will be multiple rounds of peer review before a manuscript is accepted.</p>
<p>Peer review is typically anonymous. The names of peer reviewers are not known to anyone except the editor. Researchers self-report that they would be less likely to review for a journal if their identity is made public, and anecdotally mention that signed reviews would make it more difficult to be honest about manuscripts they believe are poor quality <span class="citation" data-cites="mulligan_peer_2013">(<a href="references.html#ref-mulligan_peer_2013" role="doc-biblioref">Mulligan et al., 2013</a>)</span>. A more recent survey found that 50.8% of almost 3000 scientists believe that revealing the identity of reviewers would make peer review worse <span class="citation" data-cites="ross-hellauer_survey_2017">(<a href="references.html#ref-ross-hellauer_survey_2017" role="doc-biblioref">Ross-Hellauer et al., 2017</a>)</span>. Almost two-thirds of respondents believed reviewers would be less likely to deliver strong criticisms if their identity became known to the authors. The anonymity has positive, but also negative sides. As Longino (1996) writes “its confidentiality and privacy make it the vehicle for the entrenchment of established views.” Reviewers might try their best to keep certain findings, such as failures to replicate their work or claims that falsify predictions of theories they have proposed, out of the scientific literature. Scientists even have a running joke about ‘Reviewer 2’ - the reviewer who is always extremely critical about your manuscript, maybe even up to the point where the reviewer is rude and impolite, and will recommend that your manuscript should be rejected based on weak arguments. Note that there is no empirical support for the idea that reviewer 2 is actually more negative in general. Scientists share negative experiences with peer review in a Facebook group ‘Reviewer 2 Must be Stopped’.</p>
<p>Because the peer review process is central to whether the scientific manuscripts of scientists will be published, there is both a lot of criticism on peer review, concerns about the quality of peer review, attempts to fake peer review (e.g., an alliance between researchers who review their own papers, see <span class="citation" data-cites="ferguson_publishing_2014">Ferguson et al. (<a href="references.html#ref-ferguson_publishing_2014" role="doc-biblioref">2014</a>)</span>), as well as experiments with improving peer review. Recent developments are open peer review, where the content of reviews is made available, and signed reviews, where authors are not anonymous but attach their names to the reviews they submit), among many other innovations in peer review. After high quality peer review, a paper should be well-vetted (i.e., contain no mistakes or incorrect claims), but it is also possible the quality of the peer review is low, and a manuscript still contains mistakes or incorrect claims. Peer review is only as good as the peers. For example, when scientific peers review a manuscript, but none of the peers is well-trained in statistics, it is perfectly possible that a manuscript contains incorrect statistical inferences. Furthermore, with the increases in time-demands on academic staff, it might be increasingly difficult to find good reviewers who have the time to review a manuscript, or the reviewers might spend very little time carefully checking the manuscript. Furthermore, although it is slowly changing with the rise of open science <span class="citation" data-cites="vazire_quality_2017">(<a href="references.html#ref-vazire_quality_2017" role="doc-biblioref">Vazire, 2017</a>)</span>, peer reviewers often do not have access to the materials, data, and analysis scripts during peer review, and they have to trust those part of the process have been competently performed, which is not always the case. For these reasons, although peer review plays an important role in science when it is done well, you can not trust that all peer reviewed manuscripts are free of mistakes or incorrect claims.</p>
</section><section id="double-checking-errors." class="level3" data-number="16.2.5"><h3 data-number="16.2.5" class="anchored" data-anchor-id="double-checking-errors.">
<span class="header-section-number">16.2.5</span> Double-Checking Errors.</h3>
<p>As Friedlander <span class="citation" data-cites="friedlander_type_1964">(<a href="references.html#ref-friedlander_type_1964" role="doc-biblioref">1964</a>)</span> writes: “Errors in research do occur. Their prevalence should be viewed with alarm rather than passive acceptance as an essential concomitant of humans conducting research.” Friedlander uses himself as an example of a researcher who made an error. He computed reliability scores in a factor analysis, and found these to be surprisingly and distressingly low. He repeated the calculation, now finding a higher reliability score. As Friedlander observed: “A combination of displeasure and”distrust” of these results, plus a high sense of commitment to a nearly completed study, prompted the writer to repeat the arithmetic process used in computing the reliability coefficients. Greater care was evident in the repeated calculations, for the writer was rewarded with reliability coefficients all above .70! An additional repeat left these coefficients undamaged. Had the researcher not been displeased and surprised with the low reliability coefficients, it is doubtful that he would have repeated his calculations; a Type II error would have been committed.” Rosenthal <span class="citation" data-cites="rosenthal_experimenter_1966">(<a href="references.html#ref-rosenthal_experimenter_1966" role="doc-biblioref">1966</a>)</span> provides an overview of several studies where researchers made recording errors when writing down responses by participants that were in the direction of their hypotheses. In short, errors happen, and they are more likely to happen in ways that support the researchers’ hypothesis.</p>
<p>We all make errors, and we might not check errors if we observe results in the predicted direction. One way to prevent biased double-checking is to double-check all analyses we perform. For example, Wichters <span class="citation" data-cites="wicherts_psychology_2011">(<a href="references.html#ref-wicherts_psychology_2011" role="doc-biblioref">2011</a>)</span> writes: “my close colleagues and I have implemented a ‘co-pilot’ model for our statistical analyses, in which we share data between us for double-checking and preventing embarrassing errors.” Strand <span class="citation" data-cites="strand_error_2023">(<a href="references.html#ref-strand_error_2023" role="doc-biblioref">2023</a>)</span> similarly writes: “If we start with the assumption that mistakes will happen even when people are trying to avoid them, we must come up with methods of checking our work to find those mistakes”. She explains how building the habit to double-check work within a research collaboration will function as one layer of protection in Reason’s ‘Swiss cheese’ model of accident causation. Implementing checks in all projects also reduces the idea that work is checked due to a lack of trust, as it simply becomes part of how a group operates. Errors can also be prevented by implementing other tools, such as computationally reproducible manuscripts that prevent copy-paste errors <span class="citation" data-cites="rouder_minimizing_2019 strand_error_2023">(<a href="references.html#ref-rouder_minimizing_2019" role="doc-biblioref">Rouder et al., 2019</a>; <a href="references.html#ref-strand_error_2023" role="doc-biblioref">Strand, 2023</a>)</span>.</p>
</section><section id="the-devils-advocate" class="level3" data-number="16.2.6"><h3 data-number="16.2.6" class="anchored" data-anchor-id="the-devils-advocate">
<span class="header-section-number">16.2.6</span> The Devil’s Advocate</h3>
<p>The Devil’s advocate is a person who takes on the role of the skeptic, and argues against the accepted or desired position, regardless of whether they believe in their arguments or not. The practice originates in the Catholic church where it was used while deciding to declare a person a Saint, where the advocatus diaboli argued against the canonization of a candidate, and opposed ‘God’s advocate’ (advocatus Dei). The idea behind creating an explicit role for a Devil’s Advocate that is assigned to one person in a group is that people in general do not like to give criticism because they fear interpersonal backlash. This is, as we saw above, also the reason that peer review is typically anonymous. When groups make decisions, no one is anonymous. By assigning a specific individual to the role of a Devil’s Advocate, there is at least one person who will actively raise criticism, while they are shielded from any negative interpersonal consequences because it is their assigned duty to raise these criticisms. Additional benefits are that Devil’s advocates promote a diversity of viewpoints, and counter the pressure to conform.</p>
<p>Of course, a Devil’s Advocate needs to be listened to, and their role should not be merely ceremonial (an accusation Christopher Hitchen’s made when he was interviewed by the Vatican as a Devil’s Advocate during the decision about the beatification of Mother Theresa). It should not be possible to state that your decision procedure used a Devil’s Advocate, which was subsequently ignored, to pretend you prevented bias in decision making. Transparency about which criticism was raised, and how it was addressed, can help. Another issue is that a Devil’s Advocate needs to have sufficient knowledge about good counter-arguments to be successful. Research shows that an authentic minority dissent (i.e., including some individuals who actually hold different views than the majority) might lead to higher quality decisions than a Devil’s Advocate <span class="citation" data-cites="nemeth_devils_2001">(<a href="references.html#ref-nemeth_devils_2001" role="doc-biblioref">Nemeth et al., 2001</a>)</span>.</p>
</section><section id="adversarial-collaborations" class="level3" data-number="16.2.7"><h3 data-number="16.2.7" class="anchored" data-anchor-id="adversarial-collaborations">
<span class="header-section-number">16.2.7</span> Adversarial Collaborations</h3>
<p>One way to guarantee that there is sufficient expertise among individuals arguing different sides of a debate is to organize a collaboration between disagreeing scientists <span class="citation" data-cites="rosenthal_experimenter_1966">(<a href="references.html#ref-rosenthal_experimenter_1966" role="doc-biblioref">Rosenthal, 1966</a>)</span>. Rosenthal writes: “For the resolution of theoretical and empirical issues important enough to engage the interest of two or more competent and disagreeing scientists, it seems worthwhile to coordinate their efforts more efficiently. At the design stage the opponents might profitably collaborate in the production of a research plan which by agreement would provide a resolution of the difference of opinion. At the stage of data collection, too, the opponents may collaborate either in person or by means of assistants provided by both scientists.” If the two parties in such a collaboration each have their own preferred outcome, such as opposing theoretical predictions, research projects where both sides of a debate work together to resolve disagreements empirically are called <em>adversarial collaborations</em> <span class="citation" data-cites="mellers_frequency_2001">(<a href="references.html#ref-mellers_frequency_2001" role="doc-biblioref">Mellers et al., 2001</a>)</span>. An excellent example of a large international <strong>adversarial collaboration</strong> to design and conduct an experiment that best tested and clarified disagreements among experts in the field about the facial feedback hypothesis was conducted by <span class="citation" data-cites="coles_multi-lab_2022">Coles et al. (<a href="references.html#ref-coles_multi-lab_2022" role="doc-biblioref">2022</a>)</span>.</p>
<p>For an adversarial collaboration to be successful researchers need to be able to design an experiment that will be able to differentiate between theories, following the principles of <em>strong inference</em> <span class="citation" data-cites="platt_strong_1964">(<a href="references.html#ref-platt_strong_1964" role="doc-biblioref">Platt, 1964</a>)</span>. This may not always be possible. Furthermore, there is often a lot of auxiliary assumptions that will need to be tested before any critical test of different theories can be performed. Finally, researchers involved in such a project might try to resist the ability of the study to falsify their theory, for example by remaining strategically ambiguous about which results would be, and which results would not be, predicted by their theory <span class="citation" data-cites="frankenhuis_strategic_2022">(<a href="references.html#ref-frankenhuis_strategic_2022" role="doc-biblioref">Frankenhuis et al., 2022</a>)</span>. Despite these difficulties, adversarial collaborations hold great promise to resolve longstanding debates in the field where relatively little progress is made.</p>
<p>Beyond new empirical studies, it can also be beneficial to write collaborative review papers with a larger team of researchers with different viewpoints. The journal “Psychological Science in the Public Interest” has such collaborative review articles as it’s main aim since the year 2000 <span class="citation" data-cites="ceci_psychological_2000">(<a href="references.html#ref-ceci_psychological_2000" role="doc-biblioref">Ceci &amp; Bjork, 2000</a>)</span>. A carefully selected “blue-ribbon” team (i.e., a team consisting of exceptional researchers in the area) representing a range of viewpoints is instructed to provide a fair and balanced state of the art review on a specific topic. Such reviews can still be adversarial in nature <span class="citation" data-cites="crusius_envy_2020">(<a href="references.html#ref-crusius_envy_2020" role="doc-biblioref">Crusius et al., 2020</a>)</span>.</p>
</section><section id="red-team-science" class="level3" data-number="16.2.8"><h3 data-number="16.2.8" class="anchored" data-anchor-id="red-team-science">
<span class="header-section-number">16.2.8</span> Red Team Science</h3>
<p>All else equal, scientists should trust studies and theories that have been more critically evaluated. The more that a scientific product has been exposed to processes designed to detect flaws, the more that researchers can trust the product <span class="citation" data-cites="mayo_error_1996">(<a href="references.html#ref-mayo_error_1996" role="doc-biblioref">Mayo, 1996</a>)</span>. Yet, there are barriers to adopting critical approaches in science. Researchers are susceptible to biases, such as confirmation bias, or they may gain a competitive advantage for jobs, funding, and promotions by sacrificing rigor in order to produce larger quantities of research. And even if researchers are transparent enough to allow others to critically examine their materials, code, and ideas, there is little incentive for others–including peer reviewers–to do so. We can only trust findings in a field if there are self-correcting mechanisms that guarantee critical appraisal that will identify and correct erroneous conclusions <span class="citation" data-cites="vazire_where_2022">(<a href="references.html#ref-vazire_where_2022" role="doc-biblioref">Vazire &amp; Holcombe, 2022</a>)</span>.</p>
<p>Finding ways to prove ourselves wrong is a scientific ideal, but it is rarely scientific practice. Openness to critique is nowhere near as widespread as researchers like to think. Scientists rarely implement procedures to receive and incorporate push back. Most formal mechanisms are tied to the peer-review, which typically happens after the research is completed and the manuscript written up, but it is likely more beneficial to receive peer feedback before the data is collected <span class="citation" data-cites="lakens_is_2023">(<a href="references.html#ref-lakens_is_2023" role="doc-biblioref">Lakens, 2023</a>)</span>.</p>
<p>In science, “red teams” can be used in the form of a group of diverse scientific critics who criticize a research project from all angles and even act to counteract the biases of the original authors, in order to improve the final product. Red teams are used in the software industry to identify security flaws before they can be discovered and exploited by malefactors. Similarly, teams of scientists should engage with red teams at each phase of a research project and incorporate their criticism <span class="citation" data-cites="lakens_pandemic_2020">(<a href="references.html#ref-lakens_pandemic_2020" role="doc-biblioref">Lakens, 2020</a>)</span>. The logic is similar to the Registered Report publication system — in which protocols are reviewed before the results are known — except that criticism is not organized by journals or editors, but within a larger collaboration. Ideally, there is a larger amount of speedier communication between researchers and their red team than peer review allows, resulting in higher quality preprints and submissions for publication. Red Team members can be chosen because each member has an important expertise – e.g., a content expert, a statistical expert, a measurement expert, etc.) representing a much greater diversity and expertise that can typically be accomplished in peer review. Red teams are especially useful for highly sensitive or expensive research projects. They have not been used a lot in science, but some first steps are being taken to explore their usefulness.</p>
</section><section id="blinding" class="level3" data-number="16.2.9"><h3 data-number="16.2.9" class="anchored" data-anchor-id="blinding">
<span class="header-section-number">16.2.9</span> Blinding</h3>
<p>Knowledge that is not available to researchers can also not bias them. For example, some journals as authors to submit an anonymized manuscript, without author names or any other hints of the identity of the authors, to prevent this knowledge from influencing the evaluation of reviewers about the manuscript.</p>
<p><strong>Double-blind studies</strong>, where neither the participant nor the experimenter knows whether participants are in the experimental or control conditions, have the goal to prevent participant effects and experimenter effects <span class="citation" data-cites="rosenthal_experimenter_1966">(<a href="references.html#ref-rosenthal_experimenter_1966" role="doc-biblioref">Rosenthal, 1966</a>)</span>.</p>
<p>To prevent researchers from being biased during the analyses of their data they can rely on methods of <strong>blind analysis</strong>, where the data file they analyze no longer has any identifying information about which observations belong to which condition <span class="citation" data-cites="maccoun_blind_2015">(<a href="references.html#ref-maccoun_blind_2015" role="doc-biblioref">MacCoun &amp; Perlmutter, 2015</a>)</span>. A colleague uninvolved in the data analysis will create an adjusted data according to one of several possible blinding strategies. The researchers will perform the analyses, and when all analyses are performed, there is an ‘unblinding party’ where the data is unblinded, and the researchers learn whether their predictions are supported on the unblinded data, or not.</p>
</section><section id="separating-theorists-from-experimentalists" class="level3" data-number="16.2.10"><h3 data-number="16.2.10" class="anchored" data-anchor-id="separating-theorists-from-experimentalists">
<span class="header-section-number">16.2.10</span> Separating Theorists from Experimentalists</h3>
<p>Another way to reduce experimenter bias is to introduce a task division in science between those individuals who develop the hypotheses, and those who test them. Rosenthal <span class="citation" data-cites="rosenthal_experimenter_1966">(<a href="references.html#ref-rosenthal_experimenter_1966" role="doc-biblioref">1966</a>)</span> discusses the possibility of a professional experimenter whose only job it is to collect high quality data for other researchers who have developed the hypothesis to test: “The emotional investment of the professional experimenter would be in collecting the most accurate data possible. That is the performance dimension on which his rewards would be based. His emotional investment would not be in obtaining data in support of his hypothesis. Hypotheses would remain the business of the principal investigator and not of the data collector. There might, in general, be less incentive to obtain biased data by the professional experimenter than by the scientist-experimenter or the graduate student-experimenter.”</p>
<p>This distinction is commonly present in other fields, such as in experimental physics. As Junk and Lyons <span class="citation" data-cites="junk_reproducibility_2020">(<a href="references.html#ref-junk_reproducibility_2020" role="doc-biblioref">2020</a>)</span> note that there is specialization in experimental particle physics between theorists and experimentalists. One benefit is that models are fully defined by theorists before they are tested. ““The second benefit is that experimentalists almost never test theories that they themselves invented, helping to reduce possible effects of confirmation bias.” In psychology, a separation between experimentalists and theorists does not exist, but a similar divide between those who collect the data and those who interpret it theoretically can be achieved by letting other researchers write the discussion section of papers <span class="citation" data-cites="schoenegger_social_2023">(<a href="references.html#ref-schoenegger_social_2023" role="doc-biblioref">Schoenegger &amp; Pils, 2023</a>)</span>: “Outsourcing the discussion section to papers not written by the authors of the original papers plausibly reduces personal biases across the board”.</p>
</section><section id="method-of-multiple-working-hypotheses" class="level3" data-number="16.2.11"><h3 data-number="16.2.11" class="anchored" data-anchor-id="method-of-multiple-working-hypotheses">
<span class="header-section-number">16.2.11</span> Method of multiple working hypotheses</h3>
<p>In many scientific fields there is currently no tradition of specialization, and individual scientists do all tests involved in the research process – theorizing, experimental design, measurement development, data collection, data analysis, and reporting scientific results. In -<span class="citation" data-cites="chamberlin_method_1890">Chamberlin (<a href="references.html#ref-chamberlin_method_1890" role="doc-biblioref">1890</a>)</span> T. C. Chamberlin already observed how scientists tend to develop a preference for certain theories or explanations:</p>
<blockquote class="blockquote">
<p>The moment one has offered an original explanation for a phenomenon which seems satisfactory, that moment affection for his intellectual child springs into existence; and as the explanation grows into a definite theory, his parental affections cluster about his intellectual offspring, and it grows more and more dear to him, so that, while he holds it seemingly tentative, it is still lovingly tentative, and not impartially tentative. So soon as this parental affection takes possession of the mind, there is a rapid passage to the adoption of the theory. There is an unconscious selection and magnifying of the phenomena that fall into harmony with the theory and support it, and an unconscious neglect of those that fail of coincidence. The mind lingers with pleasure upon the facts that fall happily into the embrace of the theory, and feels a natural coldness toward those that seem refractory. Instinctively there is a special searching-out of phenomena that support it, for the mind is led by its desires. There springs up, also, an unconscious pressing of the theory to make it fit the facts, and a pressing of the facts to make them fit the theory.</p>
</blockquote>
<p>To prevent such affective processing from biasing knowledge generation Chamberlin proposes the <strong>method of multiple working hypotheses</strong>: Instead of entertaining and testing a single hypothesis, a scientist actively develops a large number of working hypotheses. The idea is that none of these hypotheses has any preferential status, and a scientist can more objectively examine which is best corroborated by the data. Chamberlain writes: “The effort is to bring up into view every rational explanation of new phenomena, and to develop every tenable hypothesis respecting their cause and history. The investigator thus becomes the parent of a family of hypotheses: and, by his parental relation to all, he is forbidden to fasten his affections unduly upon any one.” If it is not possible to separate the theorists and the experimentalists, at least a single scientist can try to mentally embrace multitudes of theoretical ideas at the same time.</p>
<p>Platt <span class="citation" data-cites="platt_strong_1964">(<a href="references.html#ref-platt_strong_1964" role="doc-biblioref">1964</a>)</span> was inspired by Chamberlain when developing his ideas on <strong>strong inference</strong>: “It seems to me that Chamberlin has hit on the explanation - and the cure - for many of our problems in the sciences. The conflict and exclusion of alternatives that is necessary to sharp inductive inference has been all too often a conflict between men, each with his single Ruling Theory. But whenever each man begins to have multiple working hypotheses, it becomes purely a conflict between ideas. It becomes much easier then for each of us to aim every day at conclusive disproofs - at strong inference – without either reluctance or combativeness. In fact, when there are multiple hypotheses which are not anyone’s”personal property” and when there are crucial experiments to test them, the daily life in the laboratory takes on an interest and excitement it never had, and the students can hardly wait to get to work to see how the detective story will come out.” Of course this approach requires that researchers become experts in each theoretical model, and have the skill and expertise required to test all different hypotheses.</p>
</section></section><section id="conclusion" class="level2" data-number="16.3"><h2 data-number="16.3" class="anchored" data-anchor-id="conclusion">
<span class="header-section-number">16.3</span> Conclusion</h2>
<p>As Reif <span class="citation" data-cites="reif_competitive_1961">(<a href="references.html#ref-reif_competitive_1961" role="doc-biblioref">1961</a>)</span> observed: “The work situation of the scientist is not just a quiet haven for scholarly activity, ideally suited to those of introverted temperament. The pure scientist, like the businessman or lawyer, works in a social setting, and like them, he is subject to appreciable social and competitive pressures.”</p>
<p>It has been widely recognized that science is a human endeavor. Scientists have motivations and desires that might bias the claims they make. At the same time, these motivations and desires might make individuals stick to a hypothesis long enough to make a new discovery, where most other researchers would have already given up on the idea. There are certain practices in science on an institutional level and an individual level that can be used to prevent motivations and desires from leading us astray. These human factors are part of science, and we need to design science in such a way that we achieve efficient and reliable knowledge generation. It’s important to be aware of the role confirmation bias plays in science, and how you can use some of the practices described in this chapter to prevent confirmation bias from fooling yourself. It is worth keeping in mind the warning by Johann Wolfgang von Goethe from 1792:</p>
<blockquote class="blockquote">
<p>Thus we can never be too careful in our efforts to avoid drawing hasty conclusions from experiments or using them directly as proof to bear out some theory. For here at this pass, this transition from empirical evidence to judgment, cognition to application, all the inner enemies of man lie in wait: imagination, which sweeps him away on its wings before he knows his feet have left the ground; impatience; haste; self-satisfaction; rigidity; formalistic thought; prejudice; ease; frivolity; fickleness—this whole throng and its retinue. Here they lie in ambush and surprise not only the active observer but also the contemplative one who appears safe from all passion.</p>
</blockquote>
<p>To explore the topics in this chapter further, you can listen to the HPS podcast episode on <a href="https://thehpspodcast.buzzsprout.com/2180146/13413352">Collective Objectivity</a> with Fiona Fidler, or the Nullius in Verba podcast episode on <a href="https://nulliusinverba.podbean.com/e/confirmatio/">Confirmation Bias</a> and <a href="https://nulliusinverba.podbean.com/e/scepticismus/">Skepticism</a>. You can also read the book <a href="https://www.google.nl/books/edition/Nobody_s_Fool/YbqaEAAAQBAJ?hl=en&amp;gbpv=1&amp;printsec=frontcover">Nobody’s Fool</a> by Daniel Simons and Christopher Chabris.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list" style="display: none">
<div id="ref-anderson_normative_2007" class="csl-entry" role="listitem">
Anderson, M. S., Martinson, B. C., &amp; De Vries, R. (2007). Normative dissonance in science: <span>Results</span> from a national survey of <span>US</span> scientists. <em>Journal of Empirical Research on Human Research Ethics</em>, <em>2</em>(4), 3–14.
</div>
<div id="ref-azrin_control_1961" class="csl-entry" role="listitem">
Azrin, N. H., Holz, W., Ulrich, R., &amp; Goldiamond, I. (1961). The control of the content of conversation through reinforcement. <em>Journal of the Experimental Analysis of Behavior</em>, <em>4</em>, 25–30. <a href="https://doi.org/10.1901/jeab.1961.4-25">https://doi.org/10.1901/jeab.1961.4-25</a>
</div>
<div id="ref-bakan_method_1967" class="csl-entry" role="listitem">
Bakan, D. (1967). <em>On method: Toward a reconstruction of psychological investigation</em>. <span>San Francisco, Jossey-Bass</span>.
</div>
<div id="ref-barber_pitfalls_1976" class="csl-entry" role="listitem">
Barber, T. X. (1976). <em>Pitfalls in <span>Human Research</span>: <span>Ten Pivotal Points</span></em>. <span>Pergamon Press</span>.
</div>
<div id="ref-beck_modern_1957" class="csl-entry" role="listitem">
Beck, W. S. (1957). <em>Modern <span>Science</span> and the nature of life</em> (First Edition). <span>Harcourt, Brace</span>.
</div>
<div id="ref-bross_critical_1971" class="csl-entry" role="listitem">
Bross, I. D. (1971). Critical levels, statistical language and scientific inference. In <em>Foundations of statistical inference</em> (pp. 500–513). <span>Holt, Rinehart and Winston</span>.
</div>
<div id="ref-ceci_psychological_2000" class="csl-entry" role="listitem">
Ceci, S. J., &amp; Bjork, R. A. (2000). Psychological <span>Science</span> in the <span>Public Interest</span>: <span>The Case</span> for <span>Juried Analyses</span>. <em>Psychological Science</em>, <em>11</em>(3), 177–178. <a href="https://doi.org/10.1111/1467-9280.00237">https://doi.org/10.1111/1467-9280.00237</a>
</div>
<div id="ref-chamberlin_method_1890" class="csl-entry" role="listitem">
Chamberlin, T. C. (1890). The <span>Method</span> of <span>Multiple Working Hypotheses</span>. <em>Science</em>, <em>ns-15</em>(366), 92–96. <a href="https://doi.org/10.1126/science.ns-15.366.92">https://doi.org/10.1126/science.ns-15.366.92</a>
</div>
<div id="ref-chang_realism_2022" class="csl-entry" role="listitem">
Chang, H. (2022). <em>Realism for <span>Realistic People</span>: <span>A New Pragmatist Philosophy</span> of <span>Science</span></em>. <span>Cambridge University Press</span>. <a href="https://doi.org/10.1017/9781108635738">https://doi.org/10.1017/9781108635738</a>
</div>
<div id="ref-coles_multi-lab_2022" class="csl-entry" role="listitem">
Coles, N. A., March, D. S., Marmolejo-Ramos, F., Larsen, J. T., Arinze, N. C., Ndukaihe, I. L. G., Willis, M. L., Foroni, F., Reggev, N., Mokady, A., Forscher, P. S., Hunter, J. F., Kaminski, G., Yüvrük, E., Kapucu, A., Nagy, T., Hajdu, N., Tejada, J., Freitag, R. M. K., … Liuzza, M. T. (2022). A multi-lab test of the facial feedback hypothesis by the <span>Many Smiles Collaboration</span>. <em>Nature Human Behaviour</em>, <em>6</em>(12), 1731–1742. <a href="https://doi.org/10.1038/s41562-022-01458-9">https://doi.org/10.1038/s41562-022-01458-9</a>
</div>
<div id="ref-crusius_envy_2020" class="csl-entry" role="listitem">
Crusius, J., Gonzalez, M. F., Lange, J., &amp; Cohen-Charash, Y. (2020). Envy: <span>An Adversarial Review</span> and <span>Comparison</span> of <span>Two Competing Views</span>. <em>Emotion Review</em>, <em>12</em>(1), 3–21. <a href="https://doi.org/10.1177/1754073919873131">https://doi.org/10.1177/1754073919873131</a>
</div>
<div id="ref-douglas_science_2009" class="csl-entry" role="listitem">
Douglas, H. E. (2009). <em>Science, policy, and the value-free ideal</em>. <span>University of Pittsburgh Press</span>.
</div>
<div id="ref-ferguson_publishing_2014" class="csl-entry" role="listitem">
Ferguson, C., Marcus, A., &amp; Oransky, I. (2014). Publishing: <span>The</span> peer-review scam. <em>Nature</em>, <em>515</em>(7528), 480–482. <a href="https://doi.org/10.1038/515480a">https://doi.org/10.1038/515480a</a>
</div>
<div id="ref-feynman_cargo_1974" class="csl-entry" role="listitem">
Feynman, R. P. (1974). Cargo cult science. <em>Engineering and Science</em>, <em>37</em>(7), 10–13.
</div>
<div id="ref-fisher_has_1936" class="csl-entry" role="listitem">
Fisher, R. A. (1936). Has <span>Mendel</span>’s work been rediscovered? <em>Annals of Science</em>, <em>1</em>(2), 115–137.
</div>
<div id="ref-frankenhuis_strategic_2022" class="csl-entry" role="listitem">
Frankenhuis, W. E., Panchanathan, K., &amp; Smaldino, P. E. (2022). Strategic ambiguity in the social sciences. <em>Social Psychological Bulletin</em>.
</div>
<div id="ref-friedlander_type_1964" class="csl-entry" role="listitem">
Friedlander, F. (1964). Type <span>I</span> and <span>Type II Bias</span>. <em>American Psychologist</em>, <em>19</em>(3), 198–199. <a href="https://doi.org/10.1037/h0038977">https://doi.org/10.1037/h0038977</a>
</div>
<div id="ref-junk_reproducibility_2020" class="csl-entry" role="listitem">
Junk, T., &amp; Lyons, L. (2020). Reproducibility and <span>Replication</span> of <span>Experimental Particle Physics Results</span>. <em>Harvard Data Science Review</em>, <em>2</em>(4). <a href="https://doi.org/10.1162/99608f92.250f995b">https://doi.org/10.1162/99608f92.250f995b</a>
</div>
<div id="ref-kish_statistical_1959" class="csl-entry" role="listitem">
Kish, L. (1959). Some <span>Statistical Problems</span> in <span>Research Design</span>. <em>American Sociological Review</em>, <em>24</em>(3), 328–338. <a href="https://doi.org/10.2307/2089381">https://doi.org/10.2307/2089381</a>
</div>
<div id="ref-lakens_value_2019" class="csl-entry" role="listitem">
Lakens, D. (2019). The value of preregistration for psychological science: <span>A</span> conceptual analysis. <em>Japanese Psychological Review</em>, <em>62</em>(3), 221–230. <a href="https://doi.org/10.24602/sjpr.62.3_221">https://doi.org/10.24602/sjpr.62.3_221</a>
</div>
<div id="ref-lakens_pandemic_2020" class="csl-entry" role="listitem">
Lakens, D. (2020). Pandemic researchers recruit your own best critics. <em>Nature</em>, <em>581</em>(7807), 121–121. <a href="https://doi.org/10.1038/d41586-020-01392-8">https://doi.org/10.1038/d41586-020-01392-8</a>
</div>
<div id="ref-lakens_is_2023" class="csl-entry" role="listitem">
Lakens, D. (2023). Is my study useless? <span>Why</span> researchers need methodological review boards. <em>Nature</em>, <em>613</em>(7942), 9–9. <a href="https://doi.org/10.1038/d41586-022-04504-8">https://doi.org/10.1038/d41586-022-04504-8</a>
</div>
<div id="ref-langmuir_pathological_1989" class="csl-entry" role="listitem">
Langmuir, I., &amp; Hall, R. N. (1989). Pathological <span>Science</span>. <em>Physics Today</em>, <em>42</em>(10), 36–48. <a href="https://doi.org/10.1063/1.881205">https://doi.org/10.1063/1.881205</a>
</div>
<div id="ref-longino_science_1990" class="csl-entry" role="listitem">
Longino, H. E. (1990). <em>Science as <span>Social Knowledge</span>: <span>Values</span> and <span>Objectivity</span> in <span>Scientific Inquiry</span></em>. <span>Princeton University Press</span>.
</div>
<div id="ref-lubin_replicability_1957" class="csl-entry" role="listitem">
Lubin, A. (1957). Replicability as a publication criterion. <em>American Psychologist</em>, <em>12</em>, 519–520. <a href="https://doi.org/10.1037/h0039746">https://doi.org/10.1037/h0039746</a>
</div>
<div id="ref-maccoun_blind_2015" class="csl-entry" role="listitem">
MacCoun, R., &amp; Perlmutter, S. (2015). Blind analysis: <span>Hide</span> results to seek the truth. <em>Nature</em>, <em>526</em>(7572), 187–189. <a href="https://doi.org/10.1038/526187a">https://doi.org/10.1038/526187a</a>
</div>
<div id="ref-mack_need_1951" class="csl-entry" role="listitem">
Mack, R. W. (1951). The <span>Need</span> for <span>Replication Research</span> in <span>Sociology</span>. <em>American Sociological Review</em>, <em>16</em>(1), 93–94. <a href="https://doi.org/10.2307/2087978">https://doi.org/10.2307/2087978</a>
</div>
<div id="ref-mahoney_psychology_1979" class="csl-entry" role="listitem">
Mahoney, M. J. (1979). Psychology of the scientist: <span>An</span> evaluative review. <em>Social Studies of Science</em>, <em>9</em>(3), 349–375. <a href="https://doi.org/10.1177/030631277900900304">https://doi.org/10.1177/030631277900900304</a>
</div>
<div id="ref-mayo_error_1996" class="csl-entry" role="listitem">
Mayo, D. G. (1996). <em>Error and the growth of experimental knowledge</em>. <span>University of Chicago Press</span>.
</div>
<div id="ref-mellers_frequency_2001" class="csl-entry" role="listitem">
Mellers, B., Hertwig, R., &amp; Kahneman, D. (2001). Do frequency representations eliminate conjunction effects? <span>An</span> exercise in adversarial collaboration. <em>Psychological Science</em>, <em>12</em>(4), 269–275. <a href="https://doi.org/10.1111/1467-9280.00350">https://doi.org/10.1111/1467-9280.00350</a>
</div>
<div id="ref-merton_note_1942" class="csl-entry" role="listitem">
Merton, R. K. (1942). A <span>Note</span> on <span>Science</span> and <span>Democracy</span>. <em>Journal of Legal and Political Sociology</em>, <em>1</em>, 115–126.
</div>
<div id="ref-mitroff_norms_1974" class="csl-entry" role="listitem">
Mitroff, I. I. (1974). Norms and <span>Counter-Norms</span> in a <span>Select Group</span> of the <span>Apollo Moon Scientists</span>: <span>A Case Study</span> of the <span>Ambivalence</span> of <span>Scientists</span>. <em>American Sociological Review</em>, <em>39</em>(4), 579–595. <a href="https://doi.org/10.2307/2094423">https://doi.org/10.2307/2094423</a>
</div>
<div id="ref-mulligan_peer_2013" class="csl-entry" role="listitem">
Mulligan, A., Hall, L., &amp; Raphael, E. (2013). Peer review in a changing world: <span>An</span> international study measuring the attitudes of researchers. <em>Journal of the American Society for Information Science and Technology</em>, <em>64</em>(1), 132–161. <a href="https://doi.org/10.1002/asi.22798">https://doi.org/10.1002/asi.22798</a>
</div>
<div id="ref-NAP12192" class="csl-entry" role="listitem">
National Academy of Sciences, National Academy of Engineering, &amp; Institute of Medicine. (2009). <em>On being a scientist: <span>A</span> guide to responsible conduct in research: <span>Third</span> edition</em>. <span>The National Academies Press</span>. <a href="https://doi.org/10.17226/12192">https://doi.org/10.17226/12192</a>
</div>
<div id="ref-neher_probability_1967" class="csl-entry" role="listitem">
Neher, A. (1967). Probability <span>Pyramiding</span>, <span>Research Error</span> and the <span>Need</span> for <span>Independent Replication</span>. <em>The Psychological Record</em>, <em>17</em>(2), 257–262. <a href="https://doi.org/10.1007/BF03393713">https://doi.org/10.1007/BF03393713</a>
</div>
<div id="ref-nemeth_devils_2001" class="csl-entry" role="listitem">
Nemeth, C., Brown, K., &amp; Rogers, J. (2001). Devil’s advocate versus authentic dissent: Stimulating quantity and quality. <em>European Journal of Social Psychology</em>, <em>31</em>(6), 707–720. <a href="https://doi.org/10.1002/ejsp.58">https://doi.org/10.1002/ejsp.58</a>
</div>
<div id="ref-nickerson_confirmation_1998" class="csl-entry" role="listitem">
Nickerson, R. S. (1998). Confirmation bias: <span>A</span> ubiquitous phenomenon in many guises. <em>Review of General Psychology</em>, <em>2</em>(2), 175–220.
</div>
<div id="ref-platt_strong_1964" class="csl-entry" role="listitem">
Platt, J. R. (1964). Strong <span>Inference</span>: <span>Certain</span> systematic methods of scientific thinking may produce much more rapid progress than others. <em>Science</em>, <em>146</em>(3642), 347–353. <a href="https://doi.org/10.1126/science.146.3642.347">https://doi.org/10.1126/science.146.3642.347</a>
</div>
<div id="ref-radick_mendel_2022" class="csl-entry" role="listitem">
Radick, G. (2022). Mendel the fraud? <span>A</span> social history of truth in genetics. <em>Studies in History and Philosophy of Science</em>, <em>93</em>, 39–46. <a href="https://doi.org/10.1016/j.shpsa.2021.12.012">https://doi.org/10.1016/j.shpsa.2021.12.012</a>
</div>
<div id="ref-reif_competitive_1961" class="csl-entry" role="listitem">
Reif, F. (1961). The <span>Competitive World</span> of the <span>Pure Scientist</span>. <em>Science</em>, <em>134</em>(3494), 1957–1962. <a href="https://doi.org/10.1126/science.134.3494.1957">https://doi.org/10.1126/science.134.3494.1957</a>
</div>
<div id="ref-rosenthal_experimenter_1966" class="csl-entry" role="listitem">
Rosenthal, R. (1966). <em>Experimenter effects in behavioral research</em>. <span>Appleton-Century-Crofts</span>.
</div>
<div id="ref-ross-hellauer_survey_2017" class="csl-entry" role="listitem">
Ross-Hellauer, T., Deppe, A., &amp; Schmidt, B. (2017). Survey on open peer review: <span>Attitudes</span> and experience amongst editors, authors and reviewers. <em>PLOS ONE</em>, <em>12</em>(12), e0189311. <a href="https://doi.org/10.1371/journal.pone.0189311">https://doi.org/10.1371/journal.pone.0189311</a>
</div>
<div id="ref-rouder_minimizing_2019" class="csl-entry" role="listitem">
Rouder, J. N., Haaf, J. M., &amp; Snyder, H. K. (2019). Minimizing <span>Mistakes</span> in <span>Psychological Science</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>2</em>(1), 3–11. <a href="https://doi.org/10.1177/2515245918801915">https://doi.org/10.1177/2515245918801915</a>
</div>
<div id="ref-schoenegger_social_2023" class="csl-entry" role="listitem">
Schoenegger, P., &amp; Pils, R. (2023). Social sciences in crisis: On the proposed elimination of the discussion section. <em>Synthese</em>, <em>202</em>(2), 54. <a href="https://doi.org/10.1007/s11229-023-04267-3">https://doi.org/10.1007/s11229-023-04267-3</a>
</div>
<div id="ref-simmons_false-positive_2011" class="csl-entry" role="listitem">
Simmons, J. P., Nelson, L. D., &amp; Simonsohn, U. (2011). False-<span>Positive Psychology</span>: <span>Undisclosed Flexibility</span> in <span>Data Collection</span> and <span>Analysis Allows Presenting Anything</span> as <span>Significant</span>. <em>Psychological Science</em>, <em>22</em>(11), 1359–1366. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a>
</div>
<div id="ref-strand_error_2023" class="csl-entry" role="listitem">
Strand, J. F. (2023). Error tight: <span>Exercises</span> for lab groups to prevent research mistakes. <em>Psychological Methods</em>, No Pagination Specified–No Pagination Specified. <a href="https://doi.org/10.1037/met0000547">https://doi.org/10.1037/met0000547</a>
</div>
<div id="ref-uygun_tunc_epistemic_2023" class="csl-entry" role="listitem">
Uygun Tunç, D., Tunç, M. N., &amp; Lakens, D. (2023). The epistemic and pragmatic function of dichotomous claims based on statistical hypothesis tests. <em>Theory &amp; Psychology</em>, 09593543231160112. <a href="https://doi.org/10.1177/09593543231160112">https://doi.org/10.1177/09593543231160112</a>
</div>
<div id="ref-vazire_quality_2017" class="csl-entry" role="listitem">
Vazire, S. (2017). Quality <span>Uncertainty Erodes Trust</span> in <span>Science</span>. <em>Collabra: Psychology</em>, <em>3</em>(1), 1. <a href="https://doi.org/10.1525/collabra.74">https://doi.org/10.1525/collabra.74</a>
</div>
<div id="ref-vazire_where_2022" class="csl-entry" role="listitem">
Vazire, S., &amp; Holcombe, A. O. (2022). Where <span>Are</span> the <span>Self-Correcting Mechanisms</span> in <span>Science</span>? <em>Review of General Psychology</em>, <em>26</em>(2), 212–223. <a href="https://doi.org/10.1177/10892680211033912">https://doi.org/10.1177/10892680211033912</a>
</div>
<div id="ref-wason_failure_1960" class="csl-entry" role="listitem">
Wason, P. C. (1960). On the failure to eliminate hypotheses in a conceptual task. <em>Quarterly Journal of Experimental Psychology</em>, <em>12</em>(3), 129–140. <a href="https://doi.org/10.1080/17470216008416717">https://doi.org/10.1080/17470216008416717</a>
</div>
<div id="ref-wicherts_psychology_2011" class="csl-entry" role="listitem">
Wicherts, J. M. (2011). Psychology must learn a lesson from fraud case. <em>Nature</em>, <em>480</em>(7375), 7–7. <a href="https://doi.org/10.1038/480007a">https://doi.org/10.1038/480007a</a>
</div>
</div>
</section></main><!-- /main --><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script><script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    $(solveme[i]).after(" <span class='webex-icon'></span>");
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    $(selects[i]).after(" <span class='webex-icon'></span>");
  }

  update_total_correct();
}

</script><script>
// open rdrr links externally ----

var exlinks = document.querySelectorAll("a[href^='https://rdrr.io']");
var exlink_func = function(){
  window.open(this.href);
  return false;
};
for (var i = 0; i < exlinks.length; i++) {
    exlinks[i].addEventListener('click', exlink_func, false);
}

// visible second sidebar in mobile ----

function move_sidebar() {
  var toc = document.getElementById("TOC");
  var small_sidebar = document.querySelector("#quarto-sidebar .sidebar-menu-container");
  var right_sidebar = document.getElementById("quarto-margin-sidebar");

  if (window.innerWidth < 768) {
    small_sidebar.append(toc);
  } else {
    right_sidebar.append(toc);
  }
}
move_sidebar();
window.onresize = move_sidebar;
</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./15-researchintegrity.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Research Integrity</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">Lakens, D. (2022). Improving Your Statistical Inferences. Retrieved from https://lakens.github.io/statistical_inferences/. https://doi.org/10.5281/zenodo.6409077</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


</body></html>